{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd8bb6e",
   "metadata": {},
   "source": [
    "**This notebook is to evaluate the generalizability of the CNN-driven advection scheme.**\n",
    "\n",
    "We computed the statistical metrics with the solver in an epoch to see if the learned model can work well on the new dataset.\n",
    "This notebook is specifically for evaluating the robustness of solver against the changed domain direction (longitudinal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1140e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "#import Pkg\n",
    "#Pkg.add(\"Plots\")\n",
    "using Plots\n",
    "#Pkg.add(\"BenchmarkTools\")\n",
    "using BenchmarkTools\n",
    "#Pkg.add(\"Flux\")\n",
    "using Flux\n",
    "#Pkg.add(\"CSV\")\n",
    "using CSV\n",
    "#Pkg.add(\"DelimitedFiles\")\n",
    "using DelimitedFiles\n",
    "#Pkg.add(\"Statistics\")\n",
    "using Statistics\n",
    "#Pkg.add(\"StatsBase\")\n",
    "using StatsBase\n",
    "#Pkg.add(\"BSON\")\n",
    "using BSON: @save\n",
    "using BSON: @load\n",
    "#Pkg.add(\"Random\")\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f486956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pgm_ml (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Integrating through the whole timesteps using ML based advection solver ##\n",
    "## Programming advection scheme with 3 stencil (default) ##\n",
    "function pgm_ml(x, u1, model, xdim_total, nstep_total, dx, dt)\n",
    "    \n",
    "    ## Initialize\n",
    "    history_2x_learned = zeros(Float32, xdim_total, 1, nstep)\n",
    "    history_2x_learned[:,:,1] = x[:,1,1,1]\n",
    "    s1_input = x[:,:,:,1]\n",
    "    #s1_scale = s1_input\n",
    "    s1_bc = zeros(xdim_total+2)\n",
    "    \n",
    "    ## Integrate\n",
    "    for n in 1:nstep_total-1\n",
    "        # learned solver\n",
    "        #coeff_estimated = model(hcat(s1_input, u1[:,:,:,n]))\n",
    "        coeff_estimated = reshape(model(hcat(s1_input, u1[:,:,:,n])), (xdim_total, 2, 3))\n",
    "        su = s1_input\n",
    "        s1_bc = vcat( [su[1]], [su[i] for i in 1:xdim_total], [su[xdim_total]])\n",
    "        s1_scale = reshape(hcat([s1_bc[i] for i in 1:xdim_total],\n",
    "                [s1_bc[i] for i in 2:xdim_total+1],\n",
    "                [s1_bc[i] for i in 3:xdim_total+2]), xdim_total, 3)\n",
    "        s2_2x = reshape(s1_input, xdim_total) + 100*dt/dx*sum(coeff_estimated[:,1,:].*s1_scale, dims=2) \n",
    "                + 10000*(dt*dt)/(dx*dx)*sum(coeff_estimated[:,2,:].*s1_scale, dims=2)\n",
    "        \n",
    "        history_2x_learned[:,1,n+1] = s2_2x\n",
    "        s1_input = reshape(s2_2x, (xdim_total,1,1))\n",
    "    end\n",
    "    \n",
    "    return history_2x_learned\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3dd8fe16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pgm_ml (generic function with 1 method)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Integrating through the whole timesteps using ML based advection solver ##\n",
    "## Programming advection scheme with 5 stencil ##\n",
    "function pgm_ml(x, u1, model, xdim_total, nstep_total, dx, dt)\n",
    "    \n",
    "    ## Initialize\n",
    "    history_2x_learned = zeros(Float32, xdim, 1, nstep)\n",
    "    history_2x_learned[:,:,1] = x[:,1,1,1]\n",
    "    s1_input = x[:,:,:,1]\n",
    "    #s1_scale = s1_input\n",
    "    s1_bc = zeros(xdim_total+4)\n",
    "    \n",
    "    ## Integrate\n",
    "    for n in 1:nstep_total-1\n",
    "        # learned solver\n",
    "        #coeff_estimated = model(hcat(s1_input, u1[:,:,:,n]))\n",
    "        coeff_estimated = reshape(model(hcat(s1_input, u1[:,:,:,n])), (xdim_total, 2, 5))\n",
    "        su = s1_input\n",
    "        s1_bc = vcat( [su[1]], [su[1]], [su[i] for i in 1:xdim_total], [su[xdim_total]], [su[xdim_total]])\n",
    "        s1_scale = reshape(hcat([s1_bc[i] for i in 1:xdim_total],\n",
    "                [s1_bc[i] for i in 2:xdim_total+1],\n",
    "                [s1_bc[i] for i in 3:xdim_total+2],\n",
    "                [s1_bc[i] for i in 4:xdim_total+3],\n",
    "                [s1_bc[i] for i in 5:xdim_total+4]), xdim_total, 5)\n",
    "        s2_2x = reshape(s1_input, xdim_total) + 100*dt/dx*sum(coeff_estimated[:,1,:].*s1_scale, dims=2) \n",
    "                + 10000*(dt*dt)/(dx*dx)*sum(coeff_estimated[:,2,:].*s1_scale, dims=2)\n",
    "        \n",
    "        history_2x_learned[:,1,n+1] = s2_2x\n",
    "        s1_input = reshape(s2_2x, (xdim_total,1,1))\n",
    "    end\n",
    "    \n",
    "    return history_2x_learned\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aace5056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pgm_ml (generic function with 1 method)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Integrating through the whole timesteps using ML based advection solver ##\n",
    "## Programming advection scheme with 9 stencil ##\n",
    "function pgm_ml(x, u1, model, xdim_total, nstep_total, dx, dt)\n",
    "    \n",
    "    ## Initialize\n",
    "    history_2x_learned = zeros(Float32, xdim, 1, nstep)\n",
    "    history_2x_learned[:,:,1] = x[:,1,1,1]\n",
    "    s1_input = x[:,:,:,1]\n",
    "    #s1_scale = s1_input\n",
    "    #s1_bc = zeros(xdim_total+4)\n",
    "    \n",
    "    ## Integrate\n",
    "    for n in 1:nstep_total-1\n",
    "        # learned solver\n",
    "        #coeff_estimated = model(hcat(s1_input, u1[:,:,:,n]))\n",
    "        coeff_estimated = reshape(model(hcat(s1_input, u1[:,:,:,n])), (xdim_total, 2, 9))\n",
    "        su = s1_input\n",
    "        s1_bc = vcat( [su[1]], [su[1]], [su[1]], [su[1]], [su[i] for i in 1:xdim_total], \n",
    "            [su[xdim_total]], [su[xdim_total]], [su[xdim_total]], [su[xdim_total]])\n",
    "        s1_scale = reshape(hcat([s1_bc[i] for i in 1:xdim_total],\n",
    "                [s1_bc[i] for i in 2:xdim_total+1],\n",
    "                [s1_bc[i] for i in 3:xdim_total+2],\n",
    "                [s1_bc[i] for i in 4:xdim_total+3],\n",
    "                [s1_bc[i] for i in 5:xdim_total+4],\n",
    "                [s1_bc[i] for i in 6:xdim_total+5],\n",
    "                [s1_bc[i] for i in 7:xdim_total+6],\n",
    "                [s1_bc[i] for i in 8:xdim_total+7],\n",
    "                [s1_bc[i] for i in 9:xdim_total+8]), xdim_total, 9)\n",
    "        s2_2x = reshape(s1_input, xdim_total) + 100*dt/dx*sum(coeff_estimated[:,1,:].*s1_scale, dims=2) \n",
    "                + 10000*(dt*dt)/(dx*dx)*sum(coeff_estimated[:,2,:].*s1_scale, dims=2)\n",
    "        \n",
    "        history_2x_learned[:,1,n+1] = s2_2x\n",
    "        s1_input = reshape(s2_2x, (xdim_total,1,1))\n",
    "    end\n",
    "    \n",
    "    return history_2x_learned\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bbe49cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pgm_ml (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Integrating through the whole timesteps using ML based advection solver ##\n",
    "## Programming advection scheme with 17 stencil ##\n",
    "function pgm_ml(x, u1, model, xdim_total, nstep_total, dx, dt)\n",
    "    \n",
    "    ## Initialize\n",
    "    history_2x_learned = zeros(Float32, xdim, 1, nstep)\n",
    "    history_2x_learned[:,:,1] = x[:,1,1,1]\n",
    "    s1_input = x[:,:,:,1]\n",
    "    #s1_scale = s1_input\n",
    "    #s1_bc = zeros(xdim_total+4)\n",
    "    \n",
    "    ## Integrate\n",
    "    for n in 1:nstep_total-1\n",
    "        # learned solver\n",
    "        #coeff_estimated = model(hcat(s1_input, u1[:,:,:,n]))\n",
    "        coeff_estimated = reshape(model(hcat(s1_input, u1[:,:,:,n])), (xdim_total, 2, 17))\n",
    "        su = s1_input\n",
    "        s1_bc = vcat( [su[1]], [su[1]], [su[1]], [su[1]], [su[1]], [su[1]], [su[1]], [su[1]], [su[i] for i in 1:xdim_total], \n",
    "            [su[xdim_total]], [su[xdim_total]], [su[xdim_total]], [su[xdim_total]], \n",
    "            [su[xdim_total]], [su[xdim_total]], [su[xdim_total]], [su[xdim_total]])\n",
    "        s1_scale = reshape(hcat([s1_bc[i] for i in 1:xdim_total],\n",
    "                [s1_bc[i] for i in 2:xdim_total+1],\n",
    "                [s1_bc[i] for i in 3:xdim_total+2],\n",
    "                [s1_bc[i] for i in 4:xdim_total+3],\n",
    "                [s1_bc[i] for i in 5:xdim_total+4],\n",
    "                [s1_bc[i] for i in 6:xdim_total+5],\n",
    "                [s1_bc[i] for i in 7:xdim_total+6],\n",
    "                [s1_bc[i] for i in 8:xdim_total+7],\n",
    "                [s1_bc[i] for i in 9:xdim_total+8],\n",
    "                [s1_bc[i] for i in 10:xdim_total+9],\n",
    "                [s1_bc[i] for i in 11:xdim_total+10],\n",
    "                [s1_bc[i] for i in 12:xdim_total+11],\n",
    "                [s1_bc[i] for i in 13:xdim_total+12],\n",
    "                [s1_bc[i] for i in 14:xdim_total+13],\n",
    "                [s1_bc[i] for i in 15:xdim_total+14],\n",
    "                [s1_bc[i] for i in 16:xdim_total+15],\n",
    "                [s1_bc[i] for i in 17:xdim_total+16]), xdim_total, 17)\n",
    "        s2_2x = reshape(s1_input, xdim_total) + 100*dt/dx*sum(coeff_estimated[:,1,:].*s1_scale, dims=2) \n",
    "                + 10000*(dt*dt)/(dx*dx)*sum(coeff_estimated[:,2,:].*s1_scale, dims=2)\n",
    "        \n",
    "        history_2x_learned[:,1,n+1] = s2_2x\n",
    "        s1_input = reshape(s2_2x, (xdim_total,1,1))\n",
    "    end\n",
    "    \n",
    "    return history_2x_learned\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa486ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pgm_ml (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Integrating through the whole timesteps using ML based advection solver ##\n",
    "## Programming advection scheme with 31 stencil ##\n",
    "function pgm_ml(x, u1, model, xdim_total, nstep_total, dx, dt)\n",
    "    \n",
    "    ## Initialize\n",
    "    history_2x_learned = zeros(Float32, xdim, 1, nstep)\n",
    "    history_2x_learned[:,:,1] = x[:,1,1,1]\n",
    "    s1_input = x[:,:,:,1]\n",
    "    #s1_scale = s1_input\n",
    "    #s1_bc = zeros(xdim_total+4)\n",
    "    \n",
    "    ## Integrate\n",
    "    for n in 1:nstep_total-1\n",
    "        # learned solver\n",
    "        #coeff_estimated = model(hcat(s1_input, u1[:,:,:,n]))\n",
    "        coeff_estimated = reshape(model(hcat(s1_input, u1[:,:,:,n])), (xdim_total, 2, 31))\n",
    "        su = s1_input\n",
    "        s1_bc = vcat( [su[1]], [su[1]], [su[1]], [su[1]], [su[1]], [su[1]], [su[1]], [su[1]], [su[1]], [su[1]], \n",
    "                [su[1]], [su[1]], [su[1]], [su[1]], [su[1]], [su[i] for i in 1:xdim_total], \n",
    "                [su[xdim_total]], [su[xdim_total]], [su[xdim_total]], [su[xdim_total]], [su[xdim_total]], [su[xdim_total]],\n",
    "                [su[xdim_total]], [su[xdim_total]], [su[xdim_total]], [su[xdim_total]], [su[xdim_total]], [su[xdim_total]],\n",
    "                [su[xdim_total]], [su[xdim_total]], [su[xdim_total]])\n",
    "        s1_scale = reshape(hcat([s1_bc[i] for i in 1:xdim_total],\n",
    "                [s1_bc[i] for i in 2:xdim_total+1],\n",
    "                [s1_bc[i] for i in 3:xdim_total+2],\n",
    "                [s1_bc[i] for i in 4:xdim_total+3],\n",
    "                [s1_bc[i] for i in 5:xdim_total+4],\n",
    "                [s1_bc[i] for i in 6:xdim_total+5],\n",
    "                [s1_bc[i] for i in 7:xdim_total+6],\n",
    "                [s1_bc[i] for i in 8:xdim_total+7],\n",
    "                [s1_bc[i] for i in 9:xdim_total+8],\n",
    "                [s1_bc[i] for i in 10:xdim_total+9],\n",
    "                [s1_bc[i] for i in 11:xdim_total+10],\n",
    "                [s1_bc[i] for i in 12:xdim_total+11],\n",
    "                [s1_bc[i] for i in 13:xdim_total+12],\n",
    "                [s1_bc[i] for i in 14:xdim_total+13],\n",
    "                [s1_bc[i] for i in 15:xdim_total+14],\n",
    "                [s1_bc[i] for i in 16:xdim_total+15],\n",
    "                [s1_bc[i] for i in 17:xdim_total+16],\n",
    "                [s1_bc[i] for i in 18:xdim_total+17],\n",
    "                [s1_bc[i] for i in 19:xdim_total+18],\n",
    "                [s1_bc[i] for i in 20:xdim_total+19],\n",
    "                [s1_bc[i] for i in 21:xdim_total+20],\n",
    "                [s1_bc[i] for i in 22:xdim_total+21],\n",
    "                [s1_bc[i] for i in 23:xdim_total+22],\n",
    "                [s1_bc[i] for i in 24:xdim_total+23],\n",
    "                [s1_bc[i] for i in 25:xdim_total+24],\n",
    "                [s1_bc[i] for i in 26:xdim_total+25],\n",
    "                [s1_bc[i] for i in 27:xdim_total+26],\n",
    "                [s1_bc[i] for i in 28:xdim_total+27],\n",
    "                [s1_bc[i] for i in 29:xdim_total+28],\n",
    "                [s1_bc[i] for i in 30:xdim_total+29],\n",
    "                [s1_bc[i] for i in 31:xdim_total+30]), xdim_total, 31)\n",
    "        s2_2x = reshape(s1_input, xdim_total) + 100*dt/dx*sum(coeff_estimated[:,1,:].*s1_scale, dims=2) \n",
    "                + 10000*(dt*dt)/(dx*dx)*sum(coeff_estimated[:,2,:].*s1_scale, dims=2)\n",
    "        \n",
    "        history_2x_learned[:,1,n+1] = s2_2x\n",
    "        s1_input = reshape(s2_2x, (xdim_total,1,1))\n",
    "    end\n",
    "    \n",
    "    return history_2x_learned\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3551be8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"32\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Select the spatial and temporal coarsening factors to be evaluated\n",
    "## Specify the training epoch as well. At first, you could try the optimal epoch in training and see the results.\n",
    "## If the optimal epoch in training did not give a model converging, you could try different epoch.\n",
    "\n",
    "space_factor = 1\n",
    "time_factor = 32\n",
    "EPOCHS = 225\n",
    "if space_factor < 10\n",
    "    space_name = string(0)*string(space_factor)\n",
    "else\n",
    "    space_name = string(space_factor)\n",
    "end\n",
    "if time_factor < 10\n",
    "    time_name = string(0)*string(time_factor)\n",
    "else\n",
    "    time_name = string(time_factor)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26628e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell is used to test the trained model with different scenario.\n",
    "\n",
    "vel_GEOS_Array = readdlm(\"Generalization_tests/Longitudinal/Vel_GEOS_Jan_2019_NASA_GMAO_10_U_\"*string(space_factor)*\"x_\"*string(time_factor)*\"x.csv\", ',', Float32);\n",
    "scalar_GEOS_Array = readdlm(\"Generalization_tests/Longitudinal/VL_GEOS_Jan_2019_NASA_GMAO_10_U_\"*string(space_factor)*\"x_\"*string(time_factor)*\"x.csv\", ',', Float32);\n",
    "scalar_coarse_numerical = readdlm(\"Generalization_tests/Longitudinal/VanLeer_Coarse_GEOS_Jan_2019_NASA_GMAO_10_U_\"*string(space_factor)*\"x_\"*string(time_factor)*\"x.csv\", ',', Float32);\n",
    "\n",
    "xdim = size(vel_GEOS_Array, 1);\n",
    "nstep = size(vel_GEOS_Array, 2);\n",
    "\n",
    "Random.seed!(1)\n",
    "history = (scalar_GEOS_Array*Float32(1e7), vel_GEOS_Array/15);\n",
    "\n",
    "## Call variables\n",
    "coeff_estimated = zeros(Float32, xdim,2)\n",
    "#input = coarse_grained_s_2x[:,:]\n",
    "s2_2x = convert(Array{Float64}, zeros(xdim))\n",
    "history_2x_learned = zeros(Float32, xdim, 1, nstep);\n",
    "\n",
    "input_NN_integrate = zeros(Float32, xdim, 1, 1, nstep-1)\n",
    "u_NN_integrate = zeros(Float32, xdim, 1, 1, nstep-1)\n",
    "target_NN_integrate = zeros(Float32, xdim, 1, 1, nstep-1)\n",
    "\n",
    "input_NN_integrate[:,1,1,:] = history[1][:,1:nstep-1]\n",
    "u_NN_integrate[:,1,1,:] = history[2][:,1:nstep-1]\n",
    "target_NN_integrate[:,1,1,:] = history[1][:,2:nstep]\n",
    "\n",
    "#@load \"Train_outputs/\"*string(space_name)*\"x\"*string(time_name)*\"t/CNN_DLR_\"*string(EPOCHS)*\"EPOCHS_\"*string(space_name)*\"X\"*string(time_name)*\"X_VL_GEOS_JAN_2019_NASA_GMAO.bson_MODEL\" model\n",
    "#@load \"Train_outputs/\"*string(space_name)*\"x\"*string(time_name)*\"t_2/CNN_DLR_\"*string(EPOCHS)*\"EPOCHS_\"*string(space_name)*\"X\"*string(time_name)*\"X_VL_GEOS_JAN_2019_NASA_GMAO.bson_MODEL\" model\n",
    "@load \"Train_outputs/\"*string(space_name)*\"x\"*string(time_name)*\"t_4layer/CNN_DLR_\"*string(EPOCHS)*\"EPOCHS_\"*string(space_name)*\"X\"*string(time_name)*\"X_VL_GEOS_JAN_2019_NASA_GMAO.bson_MODEL\" model\n",
    "#@load \"Train_outputs/\"*string(space_name)*\"x\"*string(time_name)*\"t/CNN_DLR_\"*string(EPOCHS)*\"EPOCHS_1X1X_VL_GEOS_JAN_2019_NASA_GMAO.bson_MODEL\" model\n",
    "#@load \"Train_outputs/\"*string(space_name)*\"x\"*string(time_name)*\"t/CNN_DLR_\"*string(EPOCHS)*\"EPOCHS_1X2X_VL_GEOS_JAN_2019_NASA_GMAO.bson_MODEL\" model\n",
    "ps = Flux.params(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90b6ef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.321902 seconds (1.83 M allocations: 173.209 MiB, 1.03% gc time, 26.19% compilation time)\n"
     ]
    }
   ],
   "source": [
    "## Model run\n",
    "# 29N dx = 30276.7\n",
    "# 39N dx = 27034.3\n",
    "# 45N dx = 24597.8\n",
    "# Longitudinal dy = 27829.3\n",
    "@time CNN_scalar = Float32(1e-7)*pgm_ml(input_NN_integrate, u_NN_integrate, model, xdim, nstep, Float32(27829.3*space_factor), Float32(300*time_factor))[:,1,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6d26da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results:    1.344564593593181e-8   2.633898945750583e-8   0.7084246\n",
      "results:    1.4165139911411084e-6   3.8580217395051464e-5   0.00020694386\n"
     ]
    }
   ],
   "source": [
    "## Calculate error metrics\n",
    "dim = xdim*nstep\n",
    "\n",
    "mae_learned = StatsBase.L1dist(scalar_GEOS_Array, CNN_scalar)/(dim)\n",
    "rmse_learned = StatsBase.L2dist(scalar_GEOS_Array, CNN_scalar)/sqrt(dim)\n",
    "r2_learned = Statistics.cor(reshape(scalar_GEOS_Array, dim), reshape(CNN_scalar, dim))^2\n",
    "\n",
    "mae_numerical = StatsBase.L1dist(scalar_GEOS_Array, scalar_coarse_numerical)/(dim)\n",
    "rmse_numerical = StatsBase.L2dist(scalar_GEOS_Array, scalar_coarse_numerical)/sqrt(dim)\n",
    "r2_numerical = Statistics.cor(reshape(scalar_GEOS_Array, dim), reshape(scalar_coarse_numerical, dim))^2\n",
    "    \n",
    "println(\"results: \", \"   \", mae_learned, \"   \", rmse_learned, \"   \", r2_learned)\n",
    "println(\"results: \", \"   \", mae_numerical, \"   \", rmse_numerical, \"   \", r2_numerical)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
